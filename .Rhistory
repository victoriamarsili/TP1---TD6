cp = 0,
xval = 0
)
)
predicciones <- predict(modelo, val_set, type = "prob")[,2]
roc_curve <- roc(test_set$popularity, predicciones)
auc_score <- auc(roc_curve)
# Devolver una lista con el campo Score
list(Score = auc_score)
}
# Definir los límites de los hiperparámetros
limites <- list(
maxdepth = c(1L, 30L),
minsplit = c(0L, 100L),
minbucket = c(1L, 30L)
)
# Ejecutar la optimización bayesiana
result <- BayesianOptimization(
FUN = function(maxdepth, minsplit, minbucket) {
evaluar_arbol(maxdepth, minsplit, minbucket, train_set, val_set, test_set)
},
bounds = limites,
init_points = 20,
n_iter = 15,
direction = "maximize"
)
library(rBayesianOptimization)
library(rpart)
library(pROC)
library(ggplot2)
# Función para evaluar el rendimiento del árbol, con dataset como parámetro
evaluar_arbol <- function(maxdepth, minsplit, minbucket, train_set, val_set, test_set) {
modelo <- rpart(
formula = popularity ~ .,
data = train_set,
method = "class",
control = rpart.control(
maxdepth = as.integer(maxdepth),
minsplit = as.integer(minsplit),
minbucket = as.integer(minbucket),
cp = 0,
xval = 0
)
)
predicciones <- predict(modelo, val_set, type = "prob")[,2]
roc_curve <- roc(test_set$popularity, predicciones)
auc_score <- auc(roc_curve)
# Devolver una lista con el campo Score
return(list(Score = auc_score))
}
# Definir los límites de los hiperparámetros
limites <- list(
maxdepth = c(1L, 30L),
minsplit = c(0L, 100L),
minbucket = c(1L, 30L)
)
# Ejecutar la optimización bayesiana
result <- BayesianOptimization(
FUN = function(maxdepth, minsplit, minbucket) {
evaluar_arbol(maxdepth, minsplit, minbucket, train_set, val_set, test_set)
},
bounds = limites,
init_points = 20,
n_iter = 15,
direction = "maximize"
)
library(rBayesianOptimization)
library(rpart)
library(pROC)
library(ggplot2)
# Función para evaluar el rendimiento del árbol, con dataset como parámetro
evaluar_arbol <- function(maxdepth, minsplit, minbucket, training, validation) {
modelo <- rpart(
formula = popularity ~ .,
data = training,
method = "class",
control = rpart.control(
maxdepth = as.integer(maxdepth),
minsplit = as.integer(minsplit),
minbucket = as.integer(minbucket),
cp = 0,
xval = 0
)
)
predicciones <- predict(modelo, validation, type = "prob")[,2]
roc_curve <- roc(validation$popularity, predicciones)
auc_score <- auc(roc_curve)
# Devolver una lista con el campo Score
return(list(Score = auc_score))
}
# Definir los límites de los hiperparámetros
limites <- list(
maxdepth = c(1L, 30L),
minsplit = c(0L, 100L),
minbucket = c(1L, 30L)
)
# Ejecutar la optimización bayesiana
result <- BayesianOptimization(
FUN = function(maxdepth, minsplit, minbucket) {
evaluar_arbol(maxdepth, minsplit, minbucket, train_set, val_set)
},
bounds = limites,
init_points = 20,
n_iter = 15,
)
graficar_performance = function(resultado){
ggplot(resultado, aes(x = Round, y = Value)) +
geom_line(color = "blue") +
geom_point(color = "red") +
geom_hline(yintercept = 0.6562452, color = "orange", linetype = "solid", size = 1, alpha = 0.70) +
labs(title = "Progreso del valor del area bajo la curva de AUC-ROC con Optimización Bayesiana",
x = "Iteración",
y = "Área Bajo la Curva de AUC-ROC") +
theme_minimal()
}
# Extraer el historial de resultados
result_data <- result$History
mejores_hiperparametros = result$Best_Par
graficar_performance(result_data)
# Cargar las librerías necesarias
library(rpart)
library(rpart.plot)
# Crear el modelo utilizando los hiperparámetros especificados
mejor_arbol <- rpart(
formula = popularity ~ .,
data = train_set,
method = "class",
control = rpart.control(
maxdepth = 15,
minsplit = 79,
minbucket = 29,
cp = 0,
xval = 0
)
)
# Graficar el árbol utilizando rpart.plot
rpart.plot(mejor_arbol, box.palette = "red")
print(mejor_arbol$control)
predicciones_modelo = predict(mejor_arbol, newdata = test_set, type = "prob")[,2]
test_set$predicciones_optimas = predicciones_modelo
test_set$predicciones_optimas <- ifelse(test_set$predicciones_optimas >= 0.5, 1, 0)
test_set$predicciones_optimas <- as.factor(test_set$predicciones_optimas)
curva_optimizada <- roc(test_set$popularity, predicciones_modelo)
auc_score_mejor_arbol <- auc(curva_optimizada)
auc_score_mejor_arbol
# Graficar la primera curva
plot(curva_default, col = "lightblue", lwd = 3, main = "Curvas ROC", xlab = "Tasa de Falsos Positivos", ylab = "Tasa de Verdaderos Positivos")
# Añadir la segunda curva al mismo gráfico
lines(curva_optimizada, col = "red", lwd = 3)
# Añadir una leyenda para diferenciar las curvas
legend("bottomright", legend = c("Curva árbol básico", "Curva árbol optimizado"), col = c("lightblue", "red"), lwd = 3)
library(pROC)
curva_AUC_ROC = function(clase_predicha, clase_real) {
vector_predicciones = as.numeric(clase_predicha)
curva_roc = roc(clase_real, vector_predicciones)
# Extraer el área bajo la curva (AUC)
auc_value <- auc(curva_roc)
# Imprimir solo el área bajo la curva (AUC)
print(sprintf("Area bajo la curva de AUC-ROC: %f", auc_value))
plot(curva_roc, main = "Curva de AUC-ROC", col = "lightblue", lwd = 3)
return(curva_roc)
}
curva_default = curva_AUC_ROC(test_set$predicted_class_popularity, test_set$popularity)
View(test_set)
predicciones_modelo = predict(mejor_arbol, newdata = test_set, type = "prob")[,2]
test_set$predicciones_optimas = predicciones_modelo
test_set$predicciones_optimas <- ifelse(test_set$predicciones_optimas >= 0.5, TRUE, FALSE)
test_set$predicciones_optimas <- as.factor(test_set$predicciones_optimas)
curva_optimizada <- roc(test_set$popularity, predicciones_modelo)
auc_score_mejor_arbol <- auc(curva_optimizada)
auc_score_mejor_arbol
# Graficar la primera curva
plot(curva_default, col = "lightblue", lwd = 3, main = "Curvas ROC", xlab = "Tasa de Falsos Positivos", ylab = "Tasa de Verdaderos Positivos")
# Añadir la segunda curva al mismo gráfico
lines(curva_optimizada, col = "red", lwd = 3)
# Añadir una leyenda para diferenciar las curvas
legend("bottomright", legend = c("Curva árbol básico", "Curva árbol optimizado"), col = c("lightblue", "red"), lwd = 3)
predicciones_modelo = predict(mejor_arbol, newdata = test_set, type = "prob")[,2]
test_set$predicciones_optimas = predicciones_modelo
curva_optimizada <- roc(test_set$popularity, predicciones_modelo)
auc_score_mejor_arbol <- auc(curva_optimizada)
auc_score_mejor_arbol
# Graficar la primera curva
plot(curva_default, col = "lightblue", lwd = 3, main = "Curvas ROC", xlab = "Tasa de Falsos Positivos", ylab = "Tasa de Verdaderos Positivos")
# Añadir la segunda curva al mismo gráfico
lines(curva_optimizada, col = "red", lwd = 3)
# Añadir una leyenda para diferenciar las curvas
legend("bottomright", legend = c("Curva árbol básico", "Curva árbol optimizado"), col = c("lightblue", "red"), lwd = 3)
View(test_set)
predicciones_modelo = predict(mejor_arbol, newdata = test_set, type = "prob")[,2]
test_set$predicciones_optimas = predicciones_modelo
test_set$predicciones_optimas <- ifelse(test_set$predicciones_optimas >= 0.5, TRUE, FALSE)
curva_optimizada <- roc(test_set$popularity, predicciones_modelo)
auc_score_mejor_arbol <- auc(curva_optimizada)
auc_score_mejor_arbol
# Graficar la primera curva
plot(curva_default, col = "lightblue", lwd = 3, main = "Curvas ROC", xlab = "Tasa de Falsos Positivos", ylab = "Tasa de Verdaderos Positivos")
# Añadir la segunda curva al mismo gráfico
lines(curva_optimizada, col = "red", lwd = 3)
# Añadir una leyenda para diferenciar las curvas
legend("bottomright", legend = c("Curva árbol básico", "Curva árbol optimizado"), col = c("lightblue", "red"), lwd = 3)
predicciones_modelo = predict(mejor_arbol, newdata = test_set, type = "class")[,2]
predicciones_modelo = predict(mejor_arbol, newdata = test_set, type = "class")
test_set$predicciones_optimas = predicciones_modelo
curva_optimizada <- roc(test_set$popularity, predicciones_modelo)
View(test_set)
View(test_set)
predicciones_modelo = predict(mejor_arbol, newdata = test_set, type = "class")
test_set$predicciones_optimas = predicciones_modelo
curva_AUC_ROC(test_set$predicciones_optimas, test_set$popularity)
# Graficar la primera curva
plot(curva_default, col = "lightblue", lwd = 3, main = "Curvas ROC", xlab = "Tasa de Falsos Positivos", ylab = "Tasa de Verdaderos Positivos")
# Añadir la segunda curva al mismo gráfico
lines(curva_optimizada, col = "red", lwd = 3)
# Añadir una leyenda para diferenciar las curvas
legend("bottomright", legend = c("Curva árbol básico", "Curva árbol optimizado"), col = c("lightblue", "red"), lwd = 3)
predicciones_modelo = predict(mejor_arbol, newdata = test_set, type = "class")
test_set$predicciones_optimas = predicciones_modelo
curva_optimizada = curva_AUC_ROC(test_set$predicciones_optimas, test_set$popularity)
# Graficar la primera curva
plot(curva_default, col = "lightblue", lwd = 3, main = "Curvas ROC", xlab = "Tasa de Falsos Positivos", ylab = "Tasa de Verdaderos Positivos")
# Añadir la segunda curva al mismo gráfico
lines(curva_optimizada, col = "red", lwd = 3)
# Añadir una leyenda para diferenciar las curvas
legend("bottomright", legend = c("Curva árbol básico", "Curva árbol optimizado"), col = c("lightblue", "red"), lwd = 3)
predicciones_modelo = predict(mejor_arbol, newdata = test_set, type = "class")
test_set$predicciones_optimas = predicciones_modelo
curva_AUC_ROC(test_set$predicciones_optimas, test_set$popularity)
# Graficar la primera curva
plot(curva_default, col = "lightblue", lwd = 3, main = "Curvas ROC", xlab = "Tasa de Falsos Positivos", ylab = "Tasa de Verdaderos Positivos")
# Añadir la segunda curva al mismo gráfico
lines(curva_optimizada, col = "red", lwd = 3)
# Añadir una leyenda para diferenciar las curvas
legend("bottomright", legend = c("Curva árbol básico", "Curva árbol optimizado"), col = c("lightblue", "red"), lwd = 3)
predicciones_modelo = predict(mejor_arbol, newdata = test_set, type = "class")
test_set$predicciones_optimas = predicciones_modelo
curva_optimizada <- roc(test_set$popularity, predicciones_modelo)
predicciones_modelo = predict(mejor_arbol, newdata = test_set, type = "class")
test_set$predicciones_optimas = predicciones_modelo
curva_optimizada <- roc(as.numeric(test_set$popularity), as.numeric(predicciones_modelo)
auc_score_mejor_arbol <- auc(curva_optimizada)
predicciones_modelo = predict(mejor_arbol, newdata = test_set, type = "class")
test_set$predicciones_optimas = predicciones_modelo
curva_optimizada <- roc(as.numeric(test_set$popularity), as.numeric(predicciones_modelo))
auc_score_mejor_arbol <- auc(curva_optimizada)
auc_score_mejor_arbol
# Graficar la primera curva
plot(curva_default, col = "lightblue", lwd = 3, main = "Curvas ROC", xlab = "Tasa de Falsos Positivos", ylab = "Tasa de Verdaderos Positivos")
# Añadir la segunda curva al mismo gráfico
lines(curva_optimizada, col = "red", lwd = 3)
# Añadir una leyenda para diferenciar las curvas
legend("bottomright", legend = c("Curva árbol básico", "Curva árbol optimizado"), col = c("lightblue", "red"), lwd = 3)
predicciones_modelo = predict(mejor_arbol, newdata = test_set, type = "class")
test_set$predicciones_optimas = predicciones_modelo
curva_optimizada <- roc(as.numeric(test_set$popularity), as.numeric(test_set$predicciones_optimas))
auc_score_mejor_arbol <- auc(curva_optimizada)
auc_score_mejor_arbol
# Graficar la primera curva
plot(curva_default, col = "lightblue", lwd = 3, main = "Curvas ROC", xlab = "Tasa de Falsos Positivos", ylab = "Tasa de Verdaderos Positivos")
# Añadir la segunda curva al mismo gráfico
lines(curva_optimizada, col = "red", lwd = 3)
# Añadir una leyenda para diferenciar las curvas
legend("bottomright", legend = c("Curva árbol básico", "Curva árbol optimizado"), col = c("lightblue", "red"), lwd = 3)
predicciones_modelo = predict(mejor_arbol, newdata = test_set, type = "prob")[,2]
test_set$predicciones_optimas = predicciones_modelo
test_set$predicciones_optimas <- ifelse(test_set$predicciones_optimas >= 0.5, TRUE, FALSE)
test_set$predicciones_optimas <- as.factor(test_set$predicciones_optimas)
curva_optimizada <- roc(test_set$popularity, predicciones_modelo)
auc_score_mejor_arbol <- auc(curva_optimizada)
auc_score_mejor_arbol
# Graficar la primera curva
plot(curva_default, col = "lightblue", lwd = 3, main = "Curvas ROC", xlab = "Tasa de Falsos Positivos", ylab = "Tasa de Verdaderos Positivos")
# Añadir la segunda curva al mismo gráfico
lines(curva_optimizada, col = "red", lwd = 3)
# Añadir una leyenda para diferenciar las curvas
legend("bottomright", legend = c("Curva árbol básico", "Curva árbol optimizado"), col = c("lightblue", "red"), lwd = 3)
predicciones_modelo = predict(mejor_arbol, newdata = test_set, type = "class")
test_set$predicciones_optimas = predicciones_modelo
curva_optimizada <- roc(test_set$popularity, predicciones_modelo)
predicciones_modelo = predict(mejor_arbol, newdata = test_set, type = "class")
test_set$predicciones_optimas = predicciones_modelo
curva_optimizada <- roc(as.numeric(test_set$popularity), as.numeric(predicciones_modelo))
auc_score_mejor_arbol <- auc(curva_optimizada)
auc_score_mejor_arbol
# Graficar la primera curva
plot(curva_default, col = "lightblue", lwd = 3, main = "Curvas ROC", xlab = "Tasa de Falsos Positivos", ylab = "Tasa de Verdaderos Positivos")
# Añadir la segunda curva al mismo gráfico
lines(curva_optimizada, col = "red", lwd = 3)
# Añadir una leyenda para diferenciar las curvas
legend("bottomright", legend = c("Curva árbol básico", "Curva árbol optimizado"), col = c("lightblue", "red"), lwd = 3)
library(rBayesianOptimization)
library(rpart)
library(pROC)
library(ggplot2)
# Función para evaluar el rendimiento del árbol, con dataset como parámetro
evaluar_arbol <- function(maxdepth, minsplit, minbucket, training, validation) {
modelo <- rpart(
formula = popularity ~ .,
data = training,
method = "class",
control = rpart.control(
maxdepth = as.integer(maxdepth),
minsplit = as.integer(minsplit),
minbucket = as.integer(minbucket),
cp = 0,
xval = 0
)
)
predicciones <- predict(modelo, validation, type = "class")
roc_curve <- roc(as.numeric(validation$popularity), as.numeric(predicciones))
auc_score <- auc(roc_curve)
# Devolver una lista con el campo Score
return(list(Score = auc_score))
}
# Definir los límites de los hiperparámetros
limites <- list(
maxdepth = c(1L, 30L),
minsplit = c(0L, 100L),
minbucket = c(1L, 30L)
)
# Ejecutar la optimización bayesiana
result <- BayesianOptimization(
FUN = function(maxdepth, minsplit, minbucket) {
evaluar_arbol(maxdepth, minsplit, minbucket, train_set, val_set)
},
bounds = limites,
init_points = 30,
n_iter = 15,
)
graficar_performance = function(resultado){
ggplot(resultado, aes(x = Round, y = Value)) +
geom_line(color = "blue") +
geom_point(color = "red") +
geom_hline(yintercept = 0.6562452, color = "orange", linetype = "solid", size = 1, alpha = 0.70) +
labs(title = "Progreso del valor del area bajo la curva de AUC-ROC con Optimización Bayesiana",
x = "Iteración",
y = "Área Bajo la Curva de AUC-ROC") +
theme_minimal()
}
# Extraer el historial de resultados
result_data <- result$History
mejores_hiperparametros = result$Best_Par
graficar_performance(result_data)
# Cargar las librerías necesarias
library(rpart)
library(rpart.plot)
# Crear el modelo utilizando los hiperparámetros especificados
mejor_arbol <- rpart(
formula = popularity ~ .,
data = train_set,
method = "class",
control = rpart.control(
maxdepth = 15,
minsplit = 79,
minbucket = 29,
cp = 0,
xval = 0
)
)
# Graficar el árbol utilizando rpart.plot
rpart.plot(mejor_arbol, box.palette = "red")
# Cargar las librerías necesarias
library(rpart)
library(rpart.plot)
# Crear el modelo utilizando los hiperparámetros especificados
mejor_arbol <- rpart(
formula = popularity ~ .,
data = train_set,
method = "class",
control = rpart.control(
maxdepth = 11,
minsplit = 64,
minbucket = 25,
cp = 0,
xval = 0
)
)
# Graficar el árbol utilizando rpart.plot
rpart.plot(mejor_arbol, box.palette = "red")
print(mejor_arbol$control)
predicciones_modelo = predict(mejor_arbol, newdata = test_set, type = "class")
test_set$predicciones_optimas = predicciones_modelo
curva_optimizada <- roc(as.numeric(test_set$popularity), as.numeric(predicciones_modelo))
auc_score_mejor_arbol <- auc(curva_optimizada)
auc_score_mejor_arbol
# Graficar la primera curva
plot(curva_default, col = "lightblue", lwd = 3, main = "Curvas ROC", xlab = "Tasa de Falsos Positivos", ylab = "Tasa de Verdaderos Positivos")
# Añadir la segunda curva al mismo gráfico
lines(curva_optimizada, col = "red", lwd = 3)
# Añadir una leyenda para diferenciar las curvas
legend("bottomright", legend = c("Curva árbol básico", "Curva árbol optimizado"), col = c("lightblue", "red"), lwd = 3)
summary(mejor_arbol)
View(mejor_arbol)
View(muestra)
summary(muestra$time_signature)
knitr::opts_chunk$set(echo = TRUE)
library(readr)
datos = read.csv("football_teams_price_data.csv")
View(datos)
table(is.na(datos))
library(readr)
datos = read_csv("football_teams_price_data.csv", show_col_types = FALSE)
table(is.na(datos))
summary(datos$League)
datos$League
unique(datos$League)
library(readr)
datos = read_csv("football_teams_price_data.csv", show_col_types = FALSE)
subset(datos, select = -YouthAcademyRating)
subset(datos, select = -Manager)
subset(datos, select = -TeamFormation)
subset(datos, select = -PlayingStyle)
subset(datos, select = -HomeCity)
library(readr)
datos = read_csv("football_teams_price_data.csv", show_col_types = FALSE)
datos = subset(datos, select = -YouthAcademyRating)
datos = subset(datos, select = -Manager)
datos =  subset(datos, select = -TeamFormation)
datos = subset(datos, select = -PlayingStyle)
datos = subset(datos, select = -HomeCity)
n <- nrow(datos)
train_indices <- sample(1:n, size = 0.7 * n)
remaining_indices <- setdiff(1:n, train_indices)
val_indices <- sample(remaining_indices, size = 0.15 * n)
test_indices <- setdiff(remaining_indices, val_indices)
train_set <- datos[train_indices, ]
val_set <- datos[val_indices, ]
test_set <- datos[test_indices, ]
test_set_arbol = datos[test_indices, ]
mean(datos$Price)
median(datos$Price)
summary(datos$Price)
datos$Price = datos$Price/1000000
datos$Price = datos$Price/1000000
summary(datos$Price)
datos$Price = datos$Price*1000000
summary(datos$Price)
datos$Price = ifelse(datos$Price >= 2750, 1, 0)
library(rpart)
library(rpart.plot)
arbol_default = rpart(formula = Price ~ ., data = train_set, method = "class")
library(readr)
datos = read_csv("football_teams_price_data.csv", show_col_types = FALSE)
datos = subset(datos, select = -YouthAcademyRating)
datos = subset(datos, select = -Manager)
datos =  subset(datos, select = -TeamFormation)
datos = subset(datos, select = -PlayingStyle)
datos = subset(datos, select = -HomeCity)
datos$Price = datos$Price/1000000
View(datos)
datos$Price = ifelse(datos$Price >= 2750, 1, 0)
n <- nrow(datos)
train_indices <- sample(1:n, size = 0.7 * n)
remaining_indices <- setdiff(1:n, train_indices)
val_indices <- sample(remaining_indices, size = 0.15 * n)
test_indices <- setdiff(remaining_indices, val_indices)
train_set <- datos[train_indices, ]
val_set <- datos[val_indices, ]
test_set <- datos[test_indices, ]
test_set_arbol = datos[test_indices, ]
library(rpart)
library(rpart.plot)
arbol_default = rpart(formula = Price ~ ., data = train_set, method = "class")
rpart.plot(arbol, box.palette = "green")
library(rpart)
library(rpart.plot)
arbol_default = rpart(formula = Price ~ ., data = train_set, method = "class")
rpart.plot(arbol_default, box.palette = "green")
print(rpart.control())
prediccion  <- predict(arbol_default, newdata = test_set, type = "class")
test_set$clase_predicha <- prediccion
View(test_set)
library(pROC)
curva_AUC_ROC = function(clase_predicha, clase_real) {
vector_predicciones = as.numeric(clase_predicha)
curva_roc = roc(clase_real, vector_predicciones)
# Extraer el área bajo la curva (AUC)
auc_value <- auc(curva_roc)
# Imprimir solo el área bajo la curva (AUC)
print(sprintf("Area bajo la curva de AUC-ROC: %f", auc_value))
return(curva_roc)
}
curva_default = curva_AUC_ROC(test_set$clase_predicha, test_set$Price)
plot(curva_roc, main = "Curva de AUC-ROC", col = "lightblue", lwd = 3)
library(pROC)
curva_AUC_ROC = function(clase_predicha, clase_real) {
vector_predicciones = as.numeric(clase_predicha)
curva_roc = roc(clase_real, vector_predicciones)
# Extraer el área bajo la curva (AUC)
auc_value <- auc(curva_roc)
# Imprimir solo el área bajo la curva (AUC)
print(sprintf("Area bajo la curva de AUC-ROC: %f", auc_value))
return(curva_roc)
}
curva_default = curva_AUC_ROC(test_set$clase_predicha, test_set$Price)
plot(curva_default, main = "Curva de AUC-ROC", col = "lightblue", lwd = 3)
hist(datos$Price)
datos = read_csv("football_teams_price_data.csv", show_col_types = FALSE)
datos = subset(datos, select = -YouthAcademyRating)
datos = subset(datos, select = -Manager)
datos =  subset(datos, select = -TeamFormation)
datos = subset(datos, select = -PlayingStyle)
datos = subset(datos, select = -HomeCity)
hist(datos$Price)
datos$Price = datos$Price/1000000
hist(datos$Price)
datos = read_csv("breast-cancer.csv", show_col_types = FALSE)
datos = read_csv("breast-cancer.csv", show_col_types = FALSE)
View(datos)
View(data)
lung_cancer_data <- read.csv("C:/Users/maria/OneDrive/Escritorio/TP1---TD6/lung_cancer_data.csv")
View(lung_cancer_data)
