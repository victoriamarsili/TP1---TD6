# Calcular las longitudes positivas y negativas
positive_len <- sum(clase_real == 1)
negative_len <- sum(clase_real == 0)
# Normalizar la matriz de confusión
cm[1, 1] <- cm[1, 1] / negative_len
cm[1, 2] <- cm[1, 2] / positive_len
cm[2, 1] <- cm[2, 1] / negative_len
cm[2, 2] <- cm[2, 2] / positive_len
pheatmap(cm,
display_numbers = TRUE,
color = colorRampPalette(c("coral", "orange"))(50),
main = "Confusion Matrix",
number_format = "%.2f",
cluster_rows = FALSE,
cluster_cols = FALSE,
legend = TRUE,
fontsize_number = 15)
return(matriz_confusion)
}
# Llamar a la función con las columnas del dataset
matriz_de_confusion = generar_matriz_confusion(test_set$popularity, test_set$predicted_class_popularity)
accuracy <- matriz_de_confusion$overall['Accuracy']
precision <- matriz_de_confusion$byClass['Precision']
recall <- matriz_de_confusion$byClass['Recall']
f1_score <- matriz_de_confusion$byClass['F1']
accuracy
precision
recall
f1_score
library(pROC)
curva_AUC_ROC = function(clase_predicha, clase_real) {
vector_predicciones = as.numeric(clase_predicha)
curva_roc = roc(clase_real, vector_predicciones)
# Extraer el área bajo la curva (AUC)
auc_value <- auc(curva_roc)
# Imprimir solo el área bajo la curva (AUC)
print(sprintf("Area bajo la curva de AUC-ROC: %f", auc_value))
plot(curva_roc, main = "Curva de AUC-ROC", col = "lightblue", lwd = 3)
return(curva_roc)
}
curva_default = curva_AUC_ROC(test_set$predicted_class_popularity, test_set$popularity)
library(rBayesianOptimization)
library(rpart)
library(pROC)
library(ggplot2)
# Función para evaluar el rendimiento del árbol, con dataset como parámetro
evaluar_arbol <- function(maxdepth, minsplit, minbucket, training, validation) {
modelo <- rpart(
formula = popularity ~ .,
data = training,
method = "class",
control = rpart.control(
maxdepth = as.integer(maxdepth),
minsplit = as.integer(minsplit),
minbucket = as.integer(minbucket),
cp = 0,
xval = 0
)
)
predicciones <- predict(modelo, validation, type = "prob")[,2]
roc_curve <- roc(as.numeric(validation$popularity), predicciones)
auc_score <- auc(roc_curve)
# Devolver una lista con el campo Score
return(list(Score = auc_score))
}
# Definir los límites de los hiperparámetros
limites <- list(
maxdepth = c(1L, 30L),
minsplit = c(0L, 100L),
minbucket = c(1L, 30L)
)
# Ejecutar la optimización bayesiana
result <- BayesianOptimization(
FUN = function(maxdepth, minsplit, minbucket) {
evaluar_arbol(maxdepth, minsplit, minbucket, train_set, val_set)
},
bounds = limites,
init_points = 30,
n_iter = 15,
)
graficar_performance = function(resultado){
ggplot(resultado, aes(x = Round, y = Value)) +
geom_line(color = "blue") +
geom_point(color = "red") +
geom_hline(yintercept = 0.6562452, color = "orange", linetype = "solid", size = 1, alpha = 0.70) +
labs(title = "Progreso del valor del area bajo la curva de AUC-ROC con Optimización Bayesiana",
x = "Iteración",
y = "Área Bajo la Curva de AUC-ROC") +
theme_minimal()
}
# Extraer el historial de resultados
result_data <- result$History
mejores_hiperparametros = result$Best_Par
graficar_performance(result_data)
# Cargar las librerías necesarias
library(rpart)
library(rpart.plot)
# Crear el modelo utilizando los hiperparámetros especificados
mejor_arbol <- rpart(
formula = popularity ~ .,
data = train_set,
method = "class",
control = rpart.control(
maxdepth = 15,
minsplit = 100,
minbucket = 30,
cp = 0,
xval = 0
)
)
# Graficar el árbol utilizando rpart.plot
rpart.plot(mejor_arbol, box.palette = "red")
print(mejor_arbol$control)
predicciones_modelo = predict(mejor_arbol, newdata = test_set, type = "prob")[,2]
test_set$predicciones_optimas = predicciones_modelo
curva_optimizada <- roc(as.numeric(test_set$popularity), predicciones_modelo)
auc_score_mejor_arbol <- auc(curva_optimizada)
auc_score_mejor_arbol
# Graficar la primera curva
plot(curva_default, col = "lightblue", lwd = 3, main = "Curvas ROC", xlab = "Tasa de Falsos Positivos", ylab = "Tasa de Verdaderos Positivos")
# Añadir la segunda curva al mismo gráfico
lines(curva_optimizada, col = "red", lwd = 3)
# Añadir una leyenda para diferenciar las curvas
legend("bottomright", legend = c("Curva árbol básico", "Curva árbol optimizado"), col = c("lightblue", "red"), lwd = 3)
predicciones_modelo = predict(mejor_arbol, newdata = test_set, type = "prob")[,2]
test_set$predicciones_optimas = predicciones_modelo
curva_optimizada <- roc(as.numeric(test_set$popularity), predicciones_modelo)
auc_score_mejor_arbol <- auc(curva_optimizada)
auc_score_mejor_arbol
# Graficar la primera curva
plot(curva_default, col = "lightblue", lwd = 3, main = "Curvas ROC", xlab = "Tasa de Falsos Positivos", ylab = "Tasa de Verdaderos Positivos")
# Añadir la segunda curva al mismo gráfico
lines(curva_optimizada, col = "red", lwd = 3)
# Añadir una leyenda para diferenciar las curvas
legend("bottomright", legend = c("Curva árbol básico", "Curva árbol optimizado"), col = c("lightblue", "red"), lwd = 3)
graficar_performance = function(resultado){
ggplot(resultado, aes(x = Round, y = Value)) +
geom_line(color = "blue") +
geom_point(color = "red") +
geom_hline(yintercept = 0.6819935, color = "orange", linetype = "solid", size = 1, alpha = 0.70) +
labs(title = "Progreso del valor del area bajo la curva de AUC-ROC con Optimización Bayesiana",
x = "Iteración",
y = "Área Bajo la Curva de AUC-ROC") +
theme_minimal()
}
graficar_performance(result_data)
sum(test_set$popularity == 1)
library(readr)
datos = read_csv("spotify_data.csv", show_col_types = FALSE)
table(is.na(spotify_data)))
library(readr)
datos = read_csv("spotify_data.csv", show_col_types = FALSE)
table(is.na(spotify_data))
library(readr)
datos = read_csv("spotify_data.csv", show_col_types = FALSE)
table(is.na(datos))
library(readr)
datos = read_csv("spotify_data.csv", show_col_types = FALSE)
table(is.na(datos))
View(datos)
library(readr)
datos = read_csv("spotify_data.csv", show_col_types = FALSE)
table(is.na(datos))
View(datos)
datos <- datos[, -1]
datos <- datos[, -1]
write.csv(datos, "spotify_data.csv")
library(readr)
datos = read_csv("spotify_data.csv", show_col_types = FALSE)
table(is.na(datos))
View(datos)
library(readr)
datos = read_csv("spotify_data.csv", show_col_types = FALSE)
table(is.na(datos))
datos <- datos[, -1]
write.csv(datos, "C:/Users/maria/Documents/canciones.csv", row.names = FALSE)
getwd()
datos <- datos[, -1]
write.csv(datos, "C:/Users/maria/OneDrive/Documentos/canciones.csv", row.names = FALSE)
setwd("C:/Users/maria/OneDrive/Escritorio/TP1---TD6")
library(readr)
datos = read_csv("canciones.csv", show_col_types = FALSE)
table(is.na(datos))
View(datos)
library(readr)
datos = read_csv("spotify_data.csv", show_col_types = FALSE)
table(is.na(datos))
View(datos)
library(readr)
datos = read_csv("spotify_data.csv", show_col_types = FALSE)
table(is.na(datos))
datos <- datos[, -1]
write.csv(datos, "canciones2.csv", row.names = FALSE)
library(readr)
datos2 = read_csv("canciones2.csv", show_col_types = FALSE)
View(datos2)
library(readr)
datos = read_csv("spotify_data.csv", show_col_types = FALSE)
table(is.na(datos))
datos <- datos[, -1]
View(datos)
library(readr)
datos = read_csv("spotify_data.csv", show_col_types = FALSE)
table(is.na(datos))
View(datos)
datos <- datos[, -1]
# Paquete necesario
library(ggplot2)
# Gráfico de dispersión entre instrumentalness y speechiness
ggplot(datos, aes(x = instrumentalness, y = speechiness)) +
geom_point(alpha = 0.5, color = "blue") +
labs(title = "Relación entre Instrumentalness y Speechiness",
x = "Instrumentalness",
y = "Speechiness") +
theme_minimal()
# Calculamos explícitamente la correlación entre instrumentalness y speechiness
correlacion <- cor(datos$instrumentalness, datos$speechiness)
# Imprimimos el resultado
correlacion
# Aplica la función summary a cada columna en el conjunto de datos.
sapply(datos, summary)
hist(datos$popularity, main = "Histograma de popularidad", xlab = "popularidad", ylab = "frecuencia", breaks = 100, ylim = c(0, 1500))
abline(v = mean(datos$popularity), col = "red", lwd = 5)
abline(v = median(datos$popularity), col = "orange", lwd = 5)
#Convertir la popularidad a una variable numerica binaria
datos$popularity <- ifelse(datos$popularity >= 34, 1, 0)
# Obtenemos el total de filas que tiene nuestro dataset (50000)
n <- nrow(datos)
# Elegimos de manera aleatoria los indices de la muestra, asignando el 70% de los indices a los datos de entrenamiento, el 15% a datos de validación y 15% a datos de testeo
train_indices <- sample(1:n, size = 0.7 * n)
remaining_indices <- setdiff(1:n, train_indices)
val_indices <- sample(remaining_indices, size = 0.15 * n)
test_indices <- setdiff(remaining_indices, val_indices)
# Ahora creamos los datasets de train, validation y test, aleatorios, basados en los indices creados
train_set <- datos[train_indices, ]
val_set <- datos[val_indices, ]
test_set <- datos[test_indices, ]
test_set_arbol = datos[test_indices, ]
library(rpart)
library(rpart.plot)
arbol = rpart(formula = popularity ~ ., data = train_set, method = "class")
# Calculamos la media del set de entrenamiento
mean_popularity_train_set <- mean(train_set$popularity, na.rm = TRUE)
print(mean_popularity_train_set)
rpart.plot(arbol, box.palette = "orange")
print(rpart.control())
# Predicciones de clase
predictions_class <- predict(arbol, newdata = test_set, type = "class")
# Agregar las predicciones de clase al conjunto de datos
test_set$predicted_class_popularity <- predictions_class
# Predicciones de probabilidades
predictions_prob <- predict(arbol, newdata = test_set, type = "prob")
# Agregar las predicciones de probabilidades al conjunto de datos
test_set$predicted_prob_popularity <- predictions_prob
message("Columnas 'predicted_class_popularity' y 'predicted_prob_popularity' agregadas exitosamente al dataset.")
View(test_set)
library(caret)
library(recipes)
generar_matriz_confusion = function(clase_real, clase_predicha){
# Convertir las columnas a factores con los mismos niveles
clase_real_factor <- factor(clase_real, levels = c(0, 1))
clase_predicha_factor <- factor(clase_predicha, levels = c(0, 1))
# Calcular la matriz de confusión
matriz_confusion = confusionMatrix(clase_predicha_factor, clase_real_factor)
# Extraer la tabla de la matriz de confusión
cm = matriz_confusion$table
# Calcular las longitudes positivas y negativas
positive_len <- sum(clase_real == 1)
negative_len <- sum(clase_real == 0)
# Normalizar la matriz de confusión
cm[1, 1] <- cm[1, 1] / negative_len
cm[1, 2] <- cm[1, 2] / positive_len
cm[2, 1] <- cm[2, 1] / negative_len
cm[2, 2] <- cm[2, 2] / positive_len
pheatmap(cm,
display_numbers = TRUE,
color = colorRampPalette(c("coral", "orange"))(50),
main = "Confusion Matrix",
number_format = "%.2f",
cluster_rows = FALSE,
cluster_cols = FALSE,
legend = TRUE,
fontsize_number = 15)
return(matriz_confusion)
}
# Llamar a la función con las columnas del dataset
matriz_de_confusion = generar_matriz_confusion(test_set$popularity, test_set$predicted_class_popularity)
library(caret)
library(recipes)
library(pheatmap)
generar_matriz_confusion = function(clase_real, clase_predicha){
# Convertir las columnas a factores con los mismos niveles
clase_real_factor <- factor(clase_real, levels = c(0, 1))
clase_predicha_factor <- factor(clase_predicha, levels = c(0, 1))
# Calcular la matriz de confusión
matriz_confusion = confusionMatrix(clase_predicha_factor, clase_real_factor)
# Extraer la tabla de la matriz de confusión
cm = matriz_confusion$table
# Calcular las longitudes positivas y negativas
positive_len <- sum(clase_real == 1)
negative_len <- sum(clase_real == 0)
# Normalizar la matriz de confusión
cm[1, 1] <- cm[1, 1] / negative_len
cm[1, 2] <- cm[1, 2] / positive_len
cm[2, 1] <- cm[2, 1] / negative_len
cm[2, 2] <- cm[2, 2] / positive_len
pheatmap(cm,
display_numbers = TRUE,
color = colorRampPalette(c("coral", "orange"))(50),
main = "Confusion Matrix",
number_format = "%.2f",
cluster_rows = FALSE,
cluster_cols = FALSE,
legend = TRUE,
fontsize_number = 15)
return(matriz_confusion)
}
# Llamar a la función con las columnas del dataset
matriz_de_confusion = generar_matriz_confusion(test_set$popularity, test_set$predicted_class_popularity)
accuracy <- matriz_de_confusion$overall['Accuracy']
print(accuracy)
precision <- matriz_de_confusion$byClass['Precision']
recall <- matriz_de_confusion$byClass['Recall']
print(precision)
print(recall)
precision <- matriz_de_confusion$byClass['Precision']
recall <- matriz_de_confusion$byClass['Recall']
print(precision)
cat("\n")  # Línea en blanco
print(recall)
precision <- matriz_de_confusion$byClass['Precision']
recall <- matriz_de_confusion$byClass['Recall']
print(precision)
cat("\n")
print(recall)
f1_score <- matriz_de_confusion$byClass['F1']
print(f1_score)
library(pROC)
curva_AUC_ROC = function(clase_predicha, clase_real) {
vector_predicciones = as.numeric(clase_predicha)
curva_roc = roc(clase_real, vector_predicciones)
# Extraer el área bajo la curva (AUC)
auc_value <- auc(curva_roc)
# Imprimir solo el área bajo la curva (AUC)
print(sprintf("Area bajo la curva de AUC-ROC: %f", auc_value))
plot(curva_roc, main = "Curva de AUC-ROC", col = "lightblue", lwd = 3)
return(curva_roc)
}
curva_default = curva_AUC_ROC(test_set$predicted_class_popularity, test_set$popularity)
library(rBayesianOptimization)
library(rpart)
library(pROC)
library(ggplot2)
# Función para evaluar el rendimiento del árbol, con dataset como parámetro
evaluar_arbol <- function(maxdepth, minsplit, minbucket, training, validation) {
modelo <- rpart(
formula = popularity ~ .,
data = training,
method = "class",
control = rpart.control(
maxdepth = as.integer(maxdepth),
minsplit = as.integer(minsplit),
minbucket = as.integer(minbucket),
cp = 0,
xval = 0
)
)
predicciones <- predict(modelo, validation, type = "prob")[,2]
roc_curve <- roc(as.numeric(validation$popularity), predicciones)
auc_score <- auc(roc_curve)
# Devolver una lista con el campo Score
return(list(Score = auc_score))
}
# Definir los límites de los hiperparámetros
limites <- list(
maxdepth = c(1L, 30L),
minsplit = c(0L, 100L),
minbucket = c(1L, 10L)
)
# Ejecutar la optimización bayesiana
result <- BayesianOptimization(
FUN = function(maxdepth, minsplit, minbucket) {
evaluar_arbol(maxdepth, minsplit, minbucket, train_set, val_set)
},
bounds = limites,
init_points = 30,
n_iter = 15,
)
graficar_performance = function(resultado){
ggplot(resultado, aes(x = Round, y = Value)) +
geom_line(color = "blue") +
geom_point(color = "red") +
labs(title = "Progreso del valor del area bajo la curva de AUC-ROC con Optimización Bayesiana",
x = "Iteración",
y = "Área Bajo la Curva de AUC-ROC") +
theme_minimal()
}
# Extraer el historial de resultados
result_data <- result$History
mejores_hiperparametros = result$Best_Par
graficar_performance(result_data)
ggplot(result_data, aes(x = maxdepth, y = minbucket, fill = Score)) +
geom_tile() +
labs(x = "maxdepth", y = "minbucket", fill = "AUC-ROC Score") +
theme_minimal()
graficar_performance(result_data)
graficar_performance(result_data)
graficar_performance = function(resultado){
ggplot(resultado, aes(x = Round, y = Value)) +
geom_line(color = "blue") +
geom_point(color = "red") +
labs(title = "Progreso del valor del area bajo la curva de AUC-ROC con OB",
x = "Iteración",
y = "Área Bajo la Curva de AUC-ROC") +
theme_minimal()
}
graficar_performance(result_data)
mejores_hiperparametros
maxdepth_optmizado <- mejores_hiperparametros["maxdepth"]
maxdepth_optmizado
# Cargar las librerías necesarias
library(rpart)
library(rpart.plot)
maxdepth_optmizado <- mejores_hiperparametros["maxdepth"]
minsplit_optmizado <- mejores_hiperparametros["minsplit"]
minbucket_optimizado <- mejores_hiperparametros["minbucket"]
# Crear el modelo utilizando los hiperparámetros especificados
mejor_arbol <- rpart(
formula = popularity ~ .,
data = train_set,
method = "class",
control = rpart.control(
maxdepth = 15,
minsplit = 100,
minbucket = 30,
cp = 0,
xval = 0
)
)
# Graficar el árbol utilizando rpart.plot
rpart.plot(mejor_arbol, box.palette = "lightblue")
print(mejor_arbol$control)
# Cargar las librerías necesarias
library(rpart)
library(rpart.plot)
maxdepth_optmizado <- mejores_hiperparametros["maxdepth"]
minsplit_optmizado <- mejores_hiperparametros["minsplit"]
minbucket_optimizado <- mejores_hiperparametros["minbucket"]
# Crear el modelo utilizando los hiperparámetros especificados
mejor_arbol <- rpart(
formula = popularity ~ .,
data = train_set,
method = "class",
control = rpart.control(
maxdepth = maxdepth_optmizado,
minsplit = minsplit_optmizado,
minbucket = minbucket_optimizado,
cp = 0,
xval = 0
)
)
# Graficar el árbol utilizando rpart.plot
rpart.plot(mejor_arbol, box.palette = "lightblue")
print(mejor_arbol$control)
predicciones_modelo = predict(mejor_arbol, newdata = test_set, type = "prob")[,2]
test_set$predicciones_optimas = predicciones_modelo
curva_optimizada <- roc(as.numeric(test_set$popularity), predicciones_modelo)
auc_score_mejor_arbol <- auc(curva_optimizada)
auc_score_mejor_arbol
# Graficar la primera curva
plot(curva_default, col = "lightblue", lwd = 3, main = "Curvas ROC", xlab = "Tasa de Falsos Positivos", ylab = "Tasa de Verdaderos Positivos")
# Añadir la segunda curva al mismo gráfico
lines(curva_optimizada, col = "red", lwd = 3)
# Añadir una leyenda para diferenciar las curvas
legend("bottomright", legend = c("Curva árbol básico", "Curva árbol optimizado"), col = c("lightblue", "red"), lwd = 3)
curva_AUC_ROC(predicciones_modelo, test_set$popularity)
library(pROC)
curva_AUC_ROC = function(clase_predicha, clase_real) {
vector_predicciones = as.numeric(clase_predicha)
curva_roc = roc(clase_real, vector_predicciones)
# Extraer el área bajo la curva (AUC)
auc_value <- auc(curva_roc)
# Imprimir solo el área bajo la curva (AUC)
print(sprintf("Area bajo la curva de AUC-ROC: %f", auc_value))
return(auc_value, curva_roc)
}
curva_default = curva_AUC_ROC(test_set$predicted_class_popularity, test_set$popularity)
library(pROC)
curva_AUC_ROC = function(clase_predicha, clase_real) {
vector_predicciones = as.numeric(clase_predicha)
curva_roc = roc(clase_real, vector_predicciones)
# Extraer el área bajo la curva (AUC)
auc_value <- auc(curva_roc)
# Imprimir solo el área bajo la curva (AUC)
print(sprintf("Area bajo la curva de AUC-ROC: %f", auc_value))
return(list(auc = auc_value, curva_roc = curva_roc))
}
curva_default = curva_AUC_ROC(test_set$predicted_class_popularity, test_set$popularity)
predicciones_modelo = predict(mejor_arbol, newdata = test_set, type = "prob")[,2]
test_set$predicciones_optimas = predicciones_modelo
curva_AUC_ROC(predicciones_modelo, test_set$popularity)
curva_optimizada = curva_AUC_ROC(predicciones_modelo, test_set$popularity)[2]
auc_score_mejor_arbol = curva_AUC_ROC(predicciones_modelo, test_set$popularity)[1]
# Graficar la primera curva
plot(curva_default, col = "lightblue", lwd = 3, main = "Curvas ROC", xlab = "Tasa de Falsos Positivos", ylab = "Tasa de Verdaderos Positivos")
predicciones_modelo = predict(mejor_arbol, newdata = test_set, type = "prob")[,2]
test_set$predicciones_optimas = predicciones_modelo
curva_AUC_ROC(predicciones_modelo, test_set$popularity)
curva_optimizada = curva_AUC_ROC(predicciones_modelo, test_set$popularity)[2]
auc_score_mejor_arbol = curva_AUC_ROC(predicciones_modelo, test_set$popularity)[1]
# Graficar la primera curva
plot(curva_default, col = "lightblue", lwd = 3, main = "Curvas ROC", xlab = "Tasa de Falsos Positivos", ylab = "Tasa de Verdaderos Positivos")
