---
title: ''
output:
  pdf_document: default
  html_document:
    df_print: paged
editor_options:
  markdown:
    wrap: sentence
---

\
Universidad Torcuato Di Tella

Licenciatura en Tecnología Digital\
**Tecnología Digital VI: Inteligencia Artificial**

# **Introduccion al problema**

Decidimos utilizar un dataset de aproximadamente cien mil canciones de spotify con el objetivo de predecir si una cancion es popular o no en funcion del resto de las variables. Los datos fueron extraidos desde la pagina de Kaggle.

Entre las variables principales podemos mencionar:

####Variable a predecir
- Popularity: Mide la popularidad de la cancion con un valor que va de 0 a 100

###Clasificacion Binaria
Decidimos abordar la clasificacion binaria estableciendo un umbral para definir si una cancion es o no es popular en funcion de la prediccion de la variable *popularity*


###Variables Predictoras
- duration_ms: La duración de la pista en milisegundos.
- explicit: Booleano que indica si la pista contiene contenido explícito.
- danceability: Describe cuán adecuada es una pista para bailar (0.0 = menos bailable, 1.0 = más bailable).
- energy: Representa la intensidad y actividad de una pista (0.0 = baja energía, 1.0 = alta energía).
- key: La clave musical de la pista mapeada usando la notación estándar de Clase de Tono.
- loudness: Volumen general de la pista en decibelios (dB).
- mode: Indica la modalidad (mayor o menor) de la pista.
- speechiness: Detecta la presencia de palabras habladas en la pista.
- acousticness: Medida de confianza de si la pista es acústica (0.0 = no acústica, 1.0 = altamente acústica).
- instrumentalness: Predice si una pista contiene voces (0.0 = contiene voces, 1.0 = instrumental).
- liveness: Detecta la presencia de una audiencia en la grabación (0.0 = grabación de estudio, 1.0 = actuación en vivo).
- valence: Mide la positividad musical transmitida por una pista (0.0 = negativa, 1.0 = positiva).
- tempo: Tempo estimado de la pista en pulsaciones por minuto (BPM).
- time_signature: Compás estimado de la pista (3 a 7).

Aclaracion: la variable popularity esta medida a partir de las reproducciones de la cancion.
A nivel de aplicacion, a un artista le seria util poder predecir la popularidad de una nueva cancion en funcion de las variables previamente mencionadas, ya que son variables que el artista puede controlar y modificar.


FALTA JUSTIFICACION ARBOL DE DECISION

### **Preparacion de los Datos**
Lo primero que hacemos es cargar el dataset de canciones y verificar si hay valores NA en el mismo.

```{r}
library(readr)
spotify_data  = read.csv("spotify_data.csv")

table(is.na(spotify_data))
```
Vemos que no hay ningun dato faltante.

Una vez cargado, empieza la etapa de limpieza de los datos. Por ejemplo, lo primero que notamos fue que el dataset contenia muchas repeticiones de canciones por lo que eliminamos dichas observaciones repetidas, disminuyendo la cantidad total de canciones de 114000 a 73609. Posterior a eso, procedemos a eliminar las variables "track_id", "artists" "album_name" y "track_name" dado que no son relevantes para el trabajo practico.

```{r}
# Eliminar filas duplicadas basándote en la columna 'track_id'
dataset_sin_repeticiones <- spotify_data[!duplicated(spotify_data$track_id), ]

# Verificar el resultado
dim(spotify_data)               # Dimensiones del dataset original
dim(dataset_sin_repeticiones)  # Dimensiones del dataset sin duplicados
```


```{r}
# cargamos el nuevo dataset eliminando las variables anteriormente mencionadas
datos <- read_csv("cleaned_dataset.csv",col_select =-c(track_id,artists,album_name,track_name), show_col_types = FALSE)
```

Luego, hacemos un sampleo aleatorio de 50000 observaciones ya que, como dijimos previamente, nuestro dataset resultante tiene 73609 observaciones (el enunciado indica que el mismo no debe superar las 50000 observaciones)


```{r}
set.seed(33016244)

if (nrow(datos) >= 50000) {
  # Crear un vector de índices aleatorios
  indices <- sample(1:nrow(datos), 50000)
  
  # Seleccionar las filas correspondientes a esos índices
  muestra <- datos[indices, ]
  
  # Verificar el tamaño de la muestra
  nrow(muestra)
}
```
Verificamos que, efectivamente, el dataset resultante tiene 50000 observaciones.


Por ultimo, convertimos las observaciones de la variable "duration_ms" (que indica la duracion de una cancion expresada en milisegundos) de milisegundos a minutos. Tambien renombramos la variable como "duration_min"

```{r}
# Reemplazar duration_ms con la duración en minutos
muestra$duration_ms <- muestra$duration_ms / 60000

# Renombrar la variable a duration_min para reflejar el nuevo contenido
names(muestra)[names(muestra) == "duration_ms"] <- "duration_min"
```

### **Estadistica Descriptiva**

```{r}

# Apply summary to each column in the dataset
sapply(muestra, summary)

```


```{r}
hist(muestra$popularity, main = "Histograma de popularidad", xlab = "popularidad", ylab = "frecuencia")
abline(v = mean(muestra$popularity), col = "orange", lwd = 9)
```


Vemos que la media de *popularity* es 34.30186, por lo que resulta razonable establecer el umbral de popularidad para la clasificacion binaria en un valor cercano a la media. Por otro lado, el desvio estandar es 'r sd(muestra$popularity)'. Creemos que mover el umbral un desvio a la derecha seria una medida extrema, que se alejaria bastante de la media. Por lo tanto, decidimos establecer el umbral de popularidad aproxmadamente 1/4 de desvio estandar a la derecha de la media, fijando el valor en 40.
Teniendo eso en cuenta, vamos a realizar una transformación de la variable *popularity*, donde todas las observaciones mayores o iguales a 40 seran cambiadas por un 1 (la cancion es popular) y, en el caso contrario, con un 0 (la cancion no es popular).

```{r}
muestra$popularity <- ifelse(muestra$popularity >= 40, 1, 0)
```


##Division del dataset en train, validation y test

```{r}
n <- nrow(muestra)
train_indices <- sample(1:n, size = 0.7 * n)
remaining_indices <- setdiff(1:n, train_indices)
val_indices <- sample(remaining_indices, size = 0.15 * n)
test_indices <- setdiff(remaining_indices, val_indices)
train_set <- muestra[train_indices, ]
val_set <- muestra[val_indices, ]
test_set <- muestra[test_indices, ]

```

```{r}
var(muestra$duration_min)
summary(muestra$duration_min)

boxplot(muestra$duration_min)
```
```{r}
regresion_logistica = glm(formula = popularity ~ duration_min + explicit + danceability + energy + key + loudness + mode + speechiness + acousticness + instrumentalness + liveness + valence + tempo + time_signature, data = train_set)

summary(regresion_logistica)
```


REMINDER: OUTLIERS DE muestra$duration_min


REMINDER: CONVERSION DE LA VARIABLE track_genre



### **Árbol de decisión**

```{r}
library(rpart)

arbol = rpart(formula = popularity ~ duration_min + explicit + danceability + energy + key + loudness + mode + speechiness + acousticness + instrumentalness + liveness + valence + tempo + time_signature, data = train_set, method = "class")

library(rpart.plot)
rpart.plot(arbol, box.palette = "orange")

print(rpart.control())
```

###Analisis de la estructura del arbol
En el nodo raiz, podemos observar que la probabilidad de que una cancion sea popular (en esta instancia) es del 41% aproximadamente, lo cual tiene sentido ya que en esta instancia el modelo no conoce nada sobre la cancion por lo tanto esta probabilidad deberia coincidir con la media de popularity para el train_set.

```{r}
mean(train_set$popularity)
```
REMINDER: HABLAR SOBRE LA DIFERENCIA DE MEANS NUMERICA VS CATEGORICA

En adicion a esto, el modelo toma a la variable *instrumentalness* como primer filtro, estableciendo un umbral de 0.013. En este caso, el 33% del conjunto de entrenamiento cumple con esta condicion, para las cuales el arbol predice que ninguna es popular. Con el 67% restante, ahora se pregunta si *speechiness* es mayor o igual a 0.56. Podemos observar que unicamente el 1% de los datos cumple con esto. El arbol realiza este proceso de filtrado con diferentes variables hasta que el conjunto de datos no supera el *min_split* que, como vimos, esta establecido en 20 obervaciones por defecto.

REMINDER: PREGUNTAR COMO HACER ESTE ANALISIS DE MANERA IDONEA

###Análisis de los hiperparámetros

Los hiperparámetros más relevantes y su valor por defecto en rpart son: 
- minsplit = 20 --> un nodo debe tener al menos 20 observaciones para ser considerado para una división, puede suceder como no.

- minbucket = round(minsplit / 3) en este caso 20/ 3 = 6.66 ≈ 7--> por defecto, es aproximadamente un tercio de minsplit y limita el número mínimo de observaciones que debe tener un nodo terminal.

- (complexity parameter) cp = 0.01--> controla la poda del árbol, en donde un valor de 0.01 significa que una división debe disminuir el error relativo en al menos un 1% para ser considerada. Un valor de 1 se corresponde con un árbol sin divisiones, mientras que un valor de 0, con un árbol de profundidad máxima. Sólo se agregan divisiones cuando el costo de agregarlas es menor al valor de `cp`.

- maxdepth = 30 --> un valor de 30 permite que el árbol tenga hasta 30 niveles de profundidad, este hiperparámetro controla la profundiad del mismo. 

- xval = 10 --> una significación de 10 implica que se realizarán 10 validaciones cruzadas.

- maxcompete = 4 --> una estimación de 4 implica que retendrán las 4 mejores divisiones alternativas en cada nodo.

- maxsurrogate = 5 --> define el número máximo de variables sustitutas a retener en cada nodo. Las variables sustitutas se utilizan para manejar datos faltantes. Un valor de 5 significa que el algoritmo retendrá hasta 5 variables sustitutas por nodo.

- usesurrogate = 2 --> controla cómo se utilizan las variables sustitutas para manejar datos faltantes. Los valores posibles son:

  0 = No se utilizan variables sustitutas.
  1 = Se utilizan variables sustitutas solo para dividir los datos.
  2 = Se utilizan variables sustitutas tanto para dividir los datos como para asignar observaciones a nodos         terminales.

- surrogatestyle = 0 --> define el estilo de selección de variables sustitutas. Los valores posibles son:
  
  0 = Se seleccionan las variables sustitutas basándose en la reducción del error.
  1 = Se seleccionan las variables sustitutas basándose en la similitud con la variable principal.


Vamos a querer predecir, en base a los datos, si una persona *sobrevirá o no*.
Como queremos un árbol de decisión de clasificación, usaremos la función `rpart()` del paquete rpart.

`tree <- rpart(formula, data, method, parms, control, ...)`

¿En qué consiste cada uno de los parámetros de la función?

-   `formula`: permite especificar la respuesta y las variables predictoras de la forma habitual.
    Se suele establecer de la forma `respuesta ~ .` para incluir todas las posibles variables predictoras.
    En el caso de que sólo se quieran incluir algunas columnas del `data.frame` como predictoras la sintaxis pasa a ser: `respuesta ~ var_pred_selecc_1 + var_pred_selecc_2 + var_pred_selecc_3 + ...`.

-   `data`: `data.frame` (opcional; donde se evaluará la fórmula) con la muestra de entrenamiento.

-   `method`: método empleado para realizar las particiones.
    Puede ser `"anova"` (regresión), `"class"` (clasificación), `"poisson"` (regresión de Poisson) o `"exp"` (supervivencia).
    Por defecto, se selecciona a partir de la variable `respuesta` en `formula`; por ejemplo, si `respuesta` es de tipo `factor`, `method = "class"`.

-   `parms`: lista de parámetros opcionales para la partición en el caso de clasificación (o regresión de Poisson).
    Puede contener los componentes `prior` (vector de probabilidades previas; por defecto, las frecuencias observadas), `loss` (matriz de pérdidas; con ceros en la diagonal y por defecto 1 en el resto) y `split` (criterio de error; por defecto `"gini"` o alternativamente `"information"`).

-   `control`: lista con los hiperparámetros.
    Por defecto, se seleccionan mediante la función `rpart.control`, aunque también se pueden establecer en la llamada a la función principal.
    Sus principales parámetros son:

    `rpart.control(minsplit = 20, minbucket = round(minsplit/3), cp = 0.01, xval = 10, maxdepth = 30, ...)`

    -   `cp` es el parámetro de complejidad para la poda del árbol.
        Un valor de 1 se corresponde con un árbol sin divisiones, mientras que un valor de 0, con un árbol de profundidad máxima.
        Sólo se agregan divisiones cuando el costo de agregarlas es menor al valor de `cp`.

    -   `maxdepth` es la máxima profundidad permitida para el árbol.

    -   `minsplit` es el número mínimo de observaciones que debe haber en un nodo intermedio para poder dividirlo.

    -   `minbucket` es el número mínimo de observaciones en una hoja.

    -   `xval` es el número de grupos (*folds*) para validación cruzada.

### **Ahora todo junto: árbol de decisión con datos**

Armemos un árbol de decisión donde la variable *Survived* sea predicha en función de algunas de las otras columnas.

Aclaración: columnas con el ID, el nombre de la persona o el ticket no suelen ser consideradas como variables predictoras.
¿Por qué?
¿Cuán probable es que un nuevo pasajero tenga el mismo ID o el mismo nombre o el mismo ticket que un pasajero pasado?

```{r}
set.seed(22)
tree <- rpart(formula = Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked, 
              data = train, 
              method = "class")
```

En este caso, dejamos que el árbol trabaje por sí solo con los valores faltantes en edad.

```{r}
# install.packages("rpart.plot") # Descomentar si no lo tienen ya instalado.
library(rpart.plot)

rpart.plot(tree)
```

De forma similar al árbol analizado ayer, en el taller de la P03:

-   La gama del color de un nodo indica la clase predicha para las observaciones que quedan en él.

-   La intensidad del color indica cuán puro es el nodo.
    A mayor cantidad de observaciones pertenecientes a la clase predicha, mayor es la intensidad.

A diferencia del árbol analizado ayer, en el de acá:

-   Las reglas de decisión aparecen fuera, en vez de dentro, de los nodos.

-   Dentro de cada nodo, se muestra qué proporción de casos pertenecen efectivamente a la clase predicha y la proporción del total de datos que han sido agrupados en ese nodo.

También podemos hacer predicciones con nuestro árbol:

```{r}
predictions  <- predict(arbol, newdata = test_set, type = "class")

test_set$predicted_popularity <- predictions

confusion_matrix <- table(test_set$popularity, test_set$predicted_popularity)

confusion_matrix

```

¿Qué hubiese pasado si, en lugar de entrenar el modelo con valores faltantes, los hubiésemos completado con el *promedio*?

Matriz de confusión

```{r}

```

Accuracy

```{r}

```

Precision y recall

```{r}

```

F1 - score

```{r}

```

AUC-ROC

```{r}

```

Intepretacion de resultados:

[ACA LA INTERPRETACIÓN]

5. Optimización del modelo

 -> Modificar valores de los hiperparámetros maxdepth, minsplit y minbucket, y evaluar el rendimiento de cada arból con el conjunto de validación. 
 IMPORTANTE! SOLO USANDO AUC-ROC Y DEJAR FIJO CP Y XVAL EN 0
 
 [ACA]
 
 -> Realizar visualizaciones para ver como se relacionan los hiperparametros con la performance
 
 [ACA]
 
 -> Elegir el mejor árbol y medir el valor de AUC-ROC con el conjunto de testeo
 
 [ACA]
 
 -> Comparar el rendimiento entre el primer árbol y el árbol optimizado
 
 [ACA]
 
 6. Intepretación de resultados
 
 -> Presentar el árbol final, y detallar las diferencias entre el primero y el último
 
 [ACA]
 
 -> Identificar y discutir las variables más importantes según nuestro mejor árbol
 
 [ACA]
 
 7. Análisis del impacto de los valores faltantes
 
 -> Tenemos que generar 3 datasets, en cada uno falta un % de los datos de las predictoras.     En el primero 20%, el segundo 50% y el tercero 75%
 
 [ACA]
 
 -> Para cada dataset creamos un nuevo árbol optimizado (elegir hiperparam. que maximicen)
    Comparar el mejor árbol obtenido antes, con los 3 nuevos árboles
    
  [ACA]
    
  -> Analizar como cambia el rendimiento del modelo a medida que aumenta la cantidad de NAs     (Recomiendan fuertemente usar gráficos)
  
  [ACA]

8. Conclusiones y discusión

  -> Resumir los hallazgos principales del análisis.
  
  [ACA]
  
  -> Reflexionar sobre la efectividad del árbol de decisión para el problema planteado.
  
  [ACA]
  
  -> Sugerir posibles mejoras o direcciones futuras para el análisis.
  
  [ACA]

```{r}
train_withoutNA <- train                                             
train_withoutNA$Age[is.na(train_withoutNA$Age)] <- mean(train_withoutNA$Age, na.rm = TRUE)

tree_withoutNA <- rpart(formula = Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked,
                        data = train_withoutNA,
                        method = "class")

predictions_withoutNA <- predict(tree_withoutNA, newdata = test, type = "class")

data.frame("predicciones_con_na" = predictions,
           "predicciones_sin_na" = predictions_withoutNA)
```

Podemos ver que, para algunas observaciones, la predicción es diferente (e.g., fila 19).
Entonces, nos puede surgir la siguiente pregunta: ¿es mejor imputar los datos faltantes o dejar que el árbol por sí solo se encargue de ellos?

Esto y *mucho más* lo veremos en el TP1.
